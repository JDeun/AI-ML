{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델의 결과 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 모델을 훈련하는 방법과 예측에 사용하는 방법을 배웠습니다. 이는 모든 데이터 과학 프로젝트에서 필수적이지만, 단순히 모델을 훈련하고 예측에 활용하는 것만으로는 충분하지 않습니다. 이는 모델이 학습되었음에도 성능을 평가하지 않았기 때문입니다.\n",
    "\n",
    "모델을 훈련하는 데 사용하지 않은 데이터를 이용하여 모델을 평가해야 합니다. 이는 모델이 훈련된 데이터에 대해서는 예측을 잘 수행할 수 있지만, 훈련에 사용하지 않은 데이터를 모델에 사용하였을 때 성능이 좋지 않으면 사용할 수 없기 때문입니다. 따라서 이 노트북에서는 이러한 일이 발생하지 않도록 하는 방법을 배웁니다. 그렇게 하기 전에 먼저 모델이 훈련 후에 훈련되지 않은 데이터로 인해 성능이 저하되는 원인을 먼저 이해해야 합니다. 이것은 과소적합(underfitting) 또는 과대적합(overfitting) 때문일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 과소적합 vs 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과소적합은 모델이 너무 단순화되어 데이터를 제대로 설명할 수 없음을 의미합니다. 예를 들어, 비선형 관계가 있는 데이터가 있지만 선형 모델을 사용하여 학습하는 경우 과소적합이 발생할 수 있습니다. 이는 선형 모델이 데이터에서 관찰되는 비선형 관계나 추세를 설명할 수 없기 때문입니다. 따라서 과소적합된 모델을 사용하여 예측하면 성능이 저하됩니다.\n",
    "\n",
    "반면에 과대적합은 모델이 너무 잘 적합되어 데이터 세트 내의 모든 노이즈 또는 이상값도 학습했다는 것을 의미합니다. 따라서 훈련된 데이터에 대해 테스트하면 성능이 매우 우수합니다. 그러나 너무 잘 훈련되었기 때문에 일반화할 수 없으며 훈련되지 않은 데이터에 대해 테스트할 때는 성능이 좋지 않습니다.\n",
    "\n",
    "이 [문서](https://medium.com/greyatom/what-is-underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6803a989c76) 와 이 [문서 ](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229) 에서 과소적합 및 과대적합에 대한 자세한 내용을 확인하고, 흥미로운 내용을 기록하십시오. 기사 내에 수학 방정식이 있을 수 있지만 방정식을 이해할 필요는 없습니다. 기본 개념을 이해하는 것이 더 중요합니다. \n",
    "- 편향과 분산의 차이점은 무엇입니까? \n",
    "- 과소적합을 방지하는 방법은 무엇입니까? \n",
    "- 과대적합을 방지하는 방법은 무엇입니까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=pink>편향과 분산의 차이점:\n",
    "편향(Bias)은 모델이 주어진 데이터에 대해 예측을 얼마나 잘 못하는지에 대한 척도야. 예를 들어, 학습된 모델이 실제 값에서 멀리 떨어진 값을 예측하는 경우 높은 편향이 있을 수 있어.\n",
    "분산(Variance)은 모델이 같은 데이터에 대해 얼마나 민감한지를 나타내는 거야. 높은 분산은 훈련 데이터에 대해 과도하게 학습되어 새로운 데이터에는 잘 일반화되지 않을 수 있어.\n",
    "\n",
    "과소적합을 방지하는 방법:\n",
    "모델의 복잡성을 높여야 해. 예를 들어, 모델에 더 많은 층이나 파라미터를 추가하거나, 더 복잡한 알고리즘을 사용해야 해. 또한, 더 많은 학습 데이터를 사용하는 것도 도움이 돼.\n",
    "\n",
    "과대적합을 방지하는 방법: 더 많은 학습 데이터를 사용하거나, 모델의 복잡성을 줄여야 해. 예를 들어, 모델의 파라미터 수를 줄이거나, 정규화 기법을 사용하여 모델의 복잡성을 제한할 수 있어. 또한, 교차 검증을 통해 모델의 성능을 평가하고, 적절한 정규화 기법을 선택하는 것도 중요해.<font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그래프를 보십시오. 빨간색 선이 모델이고 파란색 점이 데이터 세트인 경우 모델이 과소적합인가요? 과대적합인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './resources/model1.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "답변 : 과소적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './resources/model2.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "답변 : 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 과소적합과 과대적합의 균형 맞추기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 보면 과소적합 및 과대적합 사이의 균형을 찾는 것이 중요하다는 것을 알 수 있습니다. 이를 통해 모델은 정확하면서도 훈련되지 않은 데이터에 대해서도 예측을 잘 수행할 수 있도록 일반화할 수 있습니다. 이는 모델이 다소 복잡하지만 너무 복잡하지 않아야 함을 의미합니다. 따라서 균형을 이루기 위해 노력할 수 있는 몇 가지 방법이 있습니다. 우리는 이전에 탐색한 다양한 기계 학습 기술에 대해 이러한 방법 중 일부를 시도할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 k-최근접 이웃(K-Nearest Neighbor) 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 노트북에서 KNN(K-Nearest Neighbor) 알고리즘을 적용하여 데이터를 분류하는 방법을 배웠습니다. KNN은 문제의 지점에 가장 가까운 대부분의 다른 지점을 기반으로 데이터 지점을 분류합니다. 그러나 알고리즘을 사용하기 위해서는 이웃의 수를 매개변수로 입력해야 합니다. 과소적합과 과대적합의 경우 이웃의 수가 중요한 역할을 합니다. 이는 이웃의 수가 모델이 과대, 과소적합될 가능성을 결정하기 때문입니다. 이웃 수가 많을수록 모델이 과소적합될 가능성이 줄어듭니다. 이웃 수가 너무 많으면 모델이 과대적합될 가능성이 높습니다. 따라서 모델이 상대적으로 균형을 이룰 수 있도록 적합한 이웃의 수가 있어야 합니다. 이 숫자는 데이터 세트에 따라 달라질 수 있습니다. 이제 앞서 살펴보았던 Iris Flower 데이터 세트에 대해 이웃의 숫자를 찾아봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 Iris.data에서 데이터 프레임 df로 Iris Flower 데이터 세트를 읽어야 합니다. 데이터 프레임에 열 이름이 있는지 확인하고 데이터 세트에 대한 표준 검사도 수행해야 합니다(예: 오류 데이터 및 이상값 확인). 아래 그림(출처: https://www.researchgate.net/Figure/Trollius-ranunculoide-flower-with-measured-traits_fig6_272514310) 을 참고하여 변수를 이해할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/PetalSepal1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width        class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', \"iris.data\")\n",
    "df= pd.read_csv('iris.data', header=None)\n",
    "names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]\n",
    "df.columns = names\n",
    "\n",
    "print(df.head())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 기계학습 알고리즘이 처리할 데이터를 준비하는 데 필요한 단계를 수행합니다. 먼저 특성을 x_values로 추출하고 대상 변수를 y_values로 추출합니다. 이 경우 x_values는 \"sepal_length\", \"sepal_width\", \"petal_length\" 및 \"petal_width\"가 되는 반면 y_values는 클래스가 됩니다. 또한 y_values에 레이블을 지정해야 합니다. \"Setosa\"는 0, \"Versicolor\"는 1, \"Virginica\"는 2로 지정할 수 있습니다. 이전 노트북을 참조하여 필요한 코드를 확인해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: class, dtype: int64\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "Name: class, dtype: int64\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: class, Length: 150, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 각 클래스의 데이터 포인트 수 출력\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "# 각기 다른 클래스에 대하여 다른 숫자를 지정한 딕셔너리\n",
    "# 원-핫 인코딩으로 4개 열이 아닌 3개 열만 생성되도록 0부터 시작하는 값을 사용합니다.\n",
    "label_encode = {\"class\": {\"Iris-setosa\":0, \"Iris-versicolor\":1, \"Iris-virginica\":2}}\n",
    "\n",
    "# .replace를 사용하여 다른 클래스를 숫자로 변경\n",
    "df.replace(label_encode,inplace=True)\n",
    "\n",
    "# 각 클래스의 데이터 포인트 수를 출력하여 클래스가 숫자로 변경되었는지 확인\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "# 클래스를 y_values로 추출\n",
    "y_values = df['class']\n",
    "\n",
    "print(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X와 y 값 설정\n",
    "X = df.drop(\"class\", axis=1)  # 특성 데이터\n",
    "y = df[\"class\"]  # 타겟 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기계 학습 기술로 데이터를 처리할 준비가 되었음을 확인하였다면, 과대적합과 과소적합 문제의 균형을 맞추는 방법에 초점을 맞춰야 합니다.\n",
    "\n",
    "이 균형을 결정하려면 모델이 훈련되지 않은 데이터에 적용되는 경우 모델의 성능이나 정확성을 평가할 수 있어야 합니다. 미래 데이터가 아직 생성되지 않았기 때문에 현재 데이터를 사용하여 이 평가를 수행할 수 있어야 합니다. 따라서 현재 데이터 세트는 일반적으로 2개의 다른 그룹으로 나누어 사용합니다. 한 그룹에는 데이터를 훈련하는 데 사용할 모든 훈련 데이터가 포함됩니다. 다른 그룹에는 모델 학습 단계에서 사용하지 않는 테스트 데이터가 포함됩니다. 테스트 데이터는 모델을 평가하는 데 사용되는 모델 학습 이후의 \"미래\" 데이터로 사용됩니다.\n",
    "\n",
    "데이터를 2개의 그룹으로 분할하기 위해 sklearn.model_selection의 train_test_split 함수를 사용합니다. train_test_split 함수를 가져오려면 아래 코드를 실행하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split 함수를 사용하여 데이터를 훈련 그룹과 테스트 그룹으로 나눕니다. 테스트 그룹은 일반적으로 데이터 세트의 20%에서 30%를 포함합니다. Iris Flower 데이터에 대하여 훈련 그룹 75%와 테스트 그룹 25% 기준으로 데이터를 분할할 수 있습니다. train_test_split 함수를 사용하는 방법을 이해하려면 이 [문서](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) 를 참고하세요. 학습 및 테스트 데이터를 보유하기 위해 x_train, y_train, x_test 및 y_test라는 변수를 생성할 수 있습니다. 또한 random_state를 추가하여 코드를 실행할 때마다 데이터가 항상 같은 방식으로 분할되도록 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (112, 4)\n",
      "y_train shape: (112,)\n",
      "X_test shape: (38, 4)\n",
      "y_test shape: (38,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 트레이닝 셋과 테스트 셋으로 나눔\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "\n",
    "# 출력하여 확인\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 분할한 후 이제 데이터를 표준화하거나 정규화해야 합니다. 기계 학습에 사용하는 데이터 세트를 표준화하거나 정규화하는 것은 항상 좋은 습관입니다. 이렇게 하면 모든 변수 또는 특성의 값을 유사한 범위로 확장하는 데 도움이 됩니다. 데이터를 분할한 후에는 항상 표준화 또는 정규화를 수행해야 합니다. 이는 테스트 데이터 세트가 항상 모델에 노출되지 않고, 훈련 데이터의 정규화 또는 표준화 프로세스에 사용되지 않도록 하기 위한 것입니다.\n",
    "\n",
    "이 경우 sklearn.preprocessing의 StandardScaler를 사용하여 데이터를 표준화하도록 선택합니다. .fit_transform 메서드를 x_train 데이터 값에 적용하지만 x_test 데이터에는 .transform 메서드만 적용 합니다. 아래 셀에서 표준화 프로세스를 구현합니다. 표준화 후 훈련 데이터에 대해 x_train_scale이라는 변수를 생성하고, 표준화 후 테스트 데이터에 대해 x_test scale이라는 또 다른 변수를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_scale:\n",
      "[[ 2.2256217  -1.08137229  1.78258025  1.44265925]\n",
      " [ 1.26827314  0.05691433  0.77481755  1.44265925]\n",
      " [-1.00542968  0.73988631 -1.18472103 -1.02120823]\n",
      " [-1.00542968  0.96754363 -1.18472103 -0.76185376]\n",
      " [-0.76609254 -0.85371497  0.10297575  0.27556413]\n",
      " [-1.60377252 -1.76434427 -1.35268148 -1.15088547]\n",
      " [ 0.55026173  0.51222898  0.55087029  0.5349186 ]\n",
      " [-0.76609254  2.33348758 -1.24070785 -1.41023994]\n",
      " [ 1.26827314  0.05691433  0.66284392  0.40524136]\n",
      " [ 0.07158745  0.28457166  0.6068571   0.79427307]\n",
      " [-0.28741826 -0.62605764  0.66284392  1.05362754]\n",
      " [ 1.028936    0.51222898  1.11073845  1.70201372]\n",
      " [ 0.43059316 -1.99200159  0.43889665  0.40524136]\n",
      " [ 1.62727885  1.19520095  1.33468572  1.70201372]\n",
      " [-0.40708683 -1.53668694 -0.00899788 -0.24314482]\n",
      " [ 0.19125602 -0.39840032  0.43889665  0.40524136]\n",
      " [ 0.6699303   0.28457166  0.43889665  0.40524136]\n",
      " [-0.04808112  2.10583025 -1.4086683  -1.28056271]\n",
      " [-0.64642397  1.42285828 -1.24070785 -1.28056271]\n",
      " [ 0.31092459 -0.39840032  0.55087029  0.27556413]\n",
      " [-0.5267554   0.73988631 -1.12873421 -1.28056271]\n",
      " [ 0.6699303   0.05691433  0.99876482  0.79427307]\n",
      " [-1.36443539  0.28457166 -1.18472103 -1.28056271]\n",
      " [-1.48410396  0.05691433 -1.24070785 -1.28056271]\n",
      " [-1.12509825 -1.30902962  0.43889665  0.66459584]\n",
      " [-0.88576111 -1.30902962 -0.4009056  -0.11346758]\n",
      " [ 1.028936    0.05691433  1.05475164  1.57233649]\n",
      " [-1.12509825  0.05691433 -1.24070785 -1.41023994]\n",
      " [ 1.26827314  0.05691433  0.942778    1.18330478]\n",
      " [-1.24476682 -0.17074299 -1.29669466 -1.15088547]\n",
      " [-0.04808112 -0.85371497  0.10297575  0.01620965]\n",
      " [ 0.19125602 -0.85371497  0.77481755  0.5349186 ]\n",
      " [-1.72344109  0.28457166 -1.35268148 -1.28056271]\n",
      " [ 1.14860457  0.28457166  1.22271209  1.44265925]\n",
      " [ 2.46495884  1.6505156   1.50264617  1.05362754]\n",
      " [ 0.78959886 -0.17074299  0.99876482  0.79427307]\n",
      " [ 2.10595313 -0.17074299  1.6146198   1.18330478]\n",
      " [ 0.55026173 -0.62605764  0.77481755  0.40524136]\n",
      " [-1.48410396  0.73988631 -1.29669466 -1.15088547]\n",
      " [-0.16774969 -1.08137229 -0.12097151 -0.24314482]\n",
      " [ 1.028936   -1.30902962  1.16672527  0.79427307]\n",
      " [-0.16774969 -0.62605764  0.21494939  0.14588689]\n",
      " [-1.12509825  0.05691433 -1.24070785 -1.41023994]\n",
      " [ 0.6699303  -0.62605764  1.05475164  1.18330478]\n",
      " [ 1.38794171  0.28457166  0.55087029  0.27556413]\n",
      " [-0.16774969 -0.39840032  0.2709362   0.14588689]\n",
      " [-1.00542968  1.19520095 -1.29669466 -1.28056271]\n",
      " [-0.5267554   1.87817293 -1.12873421 -1.02120823]\n",
      " [-0.88576111  1.6505156  -1.01676058 -1.02120823]\n",
      " [-0.5267554  -0.17074299  0.43889665  0.40524136]\n",
      " [ 1.86661599 -0.62605764  1.33468572  0.92395031]\n",
      " [ 0.55026173 -0.39840032  1.05475164  0.79427307]\n",
      " [ 0.90926743 -0.17074299  0.38290984  0.27556413]\n",
      " [-1.00542968  0.73988631 -1.24070785 -1.28056271]\n",
      " [-0.88576111  1.6505156  -1.18472103 -1.28056271]\n",
      " [-0.88576111  0.96754363 -1.29669466 -1.15088547]\n",
      " [ 0.78959886 -0.17074299  1.16672527  1.31298202]\n",
      " [-0.04808112 -0.85371497  0.77481755  0.92395031]\n",
      " [ 0.31092459 -0.62605764  0.15896257  0.14588689]\n",
      " [-0.40708683 -1.53668694  0.04698894 -0.11346758]\n",
      " [ 0.78959886  0.28457166  0.77481755  1.05362754]\n",
      " [ 0.78959886 -0.17074299  0.83080437  1.05362754]\n",
      " [ 0.07158745 -0.17074299  0.77481755  0.79427307]\n",
      " [ 0.31092459 -1.08137229  1.05475164  0.27556413]\n",
      " [ 0.6699303  -0.39840032  0.32692302  0.14588689]\n",
      " [-0.76609254  0.73988631 -1.29669466 -1.28056271]\n",
      " [-1.24476682  0.73988631 -1.18472103 -1.28056271]\n",
      " [-0.28741826 -0.85371497  0.2709362   0.14588689]\n",
      " [-0.88576111  0.51222898 -1.12873421 -0.891531  ]\n",
      " [-1.48410396  1.19520095 -1.52064193 -1.28056271]\n",
      " [ 0.31092459 -0.17074299  0.66284392  0.79427307]\n",
      " [-1.00542968 -1.76434427 -0.23294515 -0.24314482]\n",
      " [-0.16774969  1.6505156  -1.12873421 -1.15088547]\n",
      " [-0.76609254  0.96754363 -1.24070785 -1.28056271]\n",
      " [-0.40708683  0.96754363 -1.35268148 -1.28056271]\n",
      " [-1.12509825 -1.53668694 -0.23294515 -0.24314482]\n",
      " [-0.5267554   0.73988631 -1.24070785 -1.02120823]\n",
      " [ 1.028936    0.05691433  0.38290984  0.27556413]\n",
      " [-1.24476682 -0.17074299 -1.29669466 -1.41023994]\n",
      " [-0.40708683 -1.30902962  0.15896257  0.14588689]\n",
      " [ 0.19125602 -1.99200159  0.71883074  0.40524136]\n",
      " [-1.24476682  0.05691433 -1.18472103 -1.28056271]\n",
      " [ 1.028936    0.05691433  0.55087029  0.40524136]\n",
      " [-0.04808112 -1.08137229  0.15896257  0.01620965]\n",
      " [ 0.43059316  0.73988631  0.942778    1.44265925]\n",
      " [-1.00542968 -0.17074299 -1.18472103 -1.28056271]\n",
      " [ 0.19125602 -0.17074299  0.6068571   0.79427307]\n",
      " [-1.84310966 -0.17074299 -1.46465511 -1.41023994]\n",
      " [-0.28741826 -1.30902962  0.10297575 -0.11346758]\n",
      " [ 1.028936   -0.17074299  0.71883074  0.66459584]\n",
      " [ 2.2256217  -0.17074299  1.33468572  1.44265925]\n",
      " [ 0.55026173  0.73988631  1.05475164  1.57233649]\n",
      " [-0.40708683  2.5611449  -1.29669466 -1.28056271]\n",
      " [ 0.19125602 -1.99200159  0.15896257 -0.24314482]\n",
      " [ 2.2256217  -0.62605764  1.67060662  1.05362754]\n",
      " [ 1.74694742 -0.39840032  1.44665935  0.79427307]\n",
      " [-0.28741826 -0.17074299  0.21494939  0.14588689]\n",
      " [ 0.78959886 -0.62605764  0.49488347  0.40524136]\n",
      " [ 0.55026173  0.51222898  1.2786989   1.70201372]\n",
      " [-0.5267554   1.87817293 -1.35268148 -1.02120823]\n",
      " [ 0.6699303   0.28457166  0.88679119  1.44265925]\n",
      " [-1.00542968  0.96754363 -1.35268148 -1.15088547]\n",
      " [-0.88576111  0.96754363 -1.29669466 -1.28056271]\n",
      " [ 0.31092459 -0.62605764  0.55087029  0.01620965]\n",
      " [-1.72344109 -0.39840032 -1.29669466 -1.28056271]\n",
      " [ 1.028936   -0.17074299  0.83080437  1.44265925]\n",
      " [ 0.55026173 -0.85371497  0.66284392  0.79427307]\n",
      " [-0.16774969 -1.30902962  0.71883074  1.05362754]\n",
      " [-0.28741826 -0.39840032 -0.0649847   0.14588689]\n",
      " [-0.16774969  3.01645955 -1.24070785 -1.02120823]\n",
      " [ 1.62727885  0.28457166  1.2786989   0.79427307]\n",
      " [-1.12509825  0.05691433 -1.24070785 -1.41023994]]\n",
      "x_test_scale:\n",
      "[[ 0.55026173 -1.76434427  0.38290984  0.14588689]\n",
      " [ 0.6699303  -0.85371497  0.88679119  0.92395031]\n",
      " [-0.5267554   1.42285828 -1.24070785 -1.28056271]\n",
      " [ 0.31092459 -0.17074299  0.49488347  0.27556413]\n",
      " [-1.00542968  0.51222898 -1.29669466 -1.28056271]\n",
      " [-1.00542968 -2.44731624 -0.12097151 -0.24314482]\n",
      " [ 0.55026173 -1.30902962  0.66284392  0.40524136]\n",
      " [-0.04808112 -0.85371497  0.21494939 -0.24314482]\n",
      " [-0.88576111  0.73988631 -1.24070785 -1.28056271]\n",
      " [-0.16774969 -0.62605764  0.43889665  0.14588689]\n",
      " [-0.28741826 -0.17074299  0.43889665  0.40524136]\n",
      " [-0.04808112 -0.85371497  0.77481755  0.92395031]\n",
      " [-0.40708683 -1.76434427  0.15896257  0.14588689]\n",
      " [-1.12509825 -0.17074299 -1.29669466 -1.28056271]\n",
      " [-0.88576111  1.6505156  -1.24070785 -1.15088547]\n",
      " [ 1.14860457 -0.17074299  0.99876482  1.18330478]\n",
      " [ 0.19125602  0.73988631  0.43889665  0.5349186 ]\n",
      " [-1.72344109 -0.17074299 -1.35268148 -1.28056271]\n",
      " [-0.88576111  1.42285828 -1.24070785 -1.02120823]\n",
      " [-1.00542968  0.28457166 -1.4086683  -1.28056271]\n",
      " [ 1.50761028 -0.17074299  1.22271209  1.18330478]\n",
      " [ 0.6699303  -0.62605764  1.05475164  1.31298202]\n",
      " [ 0.43059316 -0.62605764  0.6068571   0.79427307]\n",
      " [-1.24476682  0.73988631 -1.01676058 -1.28056271]\n",
      " [ 0.07158745 -0.17074299  0.2709362   0.40524136]\n",
      " [-1.36443539  0.28457166 -1.35268148 -1.28056271]\n",
      " [-0.16774969 -0.17074299  0.2709362   0.01620965]\n",
      " [-0.40708683 -1.08137229  0.38290984  0.01620965]\n",
      " [ 1.14860457 -0.62605764  0.6068571   0.27556413]\n",
      " [ 2.2256217   1.6505156   1.67060662  1.31298202]\n",
      " [ 0.90926743 -0.39840032  0.49488347  0.14588689]\n",
      " [ 0.43059316 -0.39840032  0.32692302  0.14588689]\n",
      " [ 1.62727885 -0.17074299  1.16672527  0.5349186 ]\n",
      " [-0.04808112 -0.62605764  0.77481755  1.57233649]\n",
      " [ 0.55026173 -1.30902962  0.71883074  0.92395031]\n",
      " [-1.48410396  0.28457166 -1.29669466 -1.28056271]\n",
      " [ 1.028936    0.51222898  1.11073845  1.18330478]\n",
      " [ 1.26827314  0.28457166  1.11073845  1.44265925]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터에 대해 표준화 적용\n",
    "x_train_scale = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터에 대해 훈련 데이터의 통계치를 사용하여 표준화 적용\n",
    "x_test_scale = scaler.transform(X_test)\n",
    "\n",
    "# 출력하여 확인\n",
    "print(\"x_train_scale:\")\n",
    "print(x_train_scale)\n",
    "print(\"x_test_scale:\")\n",
    "print(x_test_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 표준화한 후 이제 KNN 알고리즘에 대한 최적의 이웃 수를 찾는 방법을 구현할 수 있습니다. 이를 위해 서로 다른 수의 이웃으로 KNN 알고리즘을 훈련하고 테스트 데이터와 비교하여 평가합니다. 그렇게 함으로써, 우리는 다른 수의 이웃에 대한 KNN 모델의 정확도를 얻을 수 있을 것입니다. 그런 다음 가장 높은 정확도에 해당하는 이웃의 수를 찾을 수 있습니다. 그 수가 최적의 이웃 수가 됩니다. 아래 코드를 실행해보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 1.0, 0.9473684210526315, 0.9473684210526315, 0.9473684210526315, 0.9736842105263158, 0.9736842105263158, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# 각 KNN 모델에 대한 정확도와 이웃 수를 저장하기 위해 빈 목록을 만듭니다.\n",
    "accuracy = []\n",
    "num_neigh = []\n",
    "\n",
    "# ii를 사용하여 값 1에서 15까지 반복합니다. 이것은 KNN 분류기의 이웃 수가 됩니다.\n",
    "for ii in range(1,16):\n",
    "    # 이웃 수를 ii로 설정\n",
    "    KNN = KNeighborsClassifier(n_neighbors=ii)\n",
    "    # 데이터로 모델 훈련 또는 피팅\n",
    "    KNN.fit(x_train_scale,y_train)\n",
    "    # .score는 테스트 데이터를 기반으로 모델의 정확도를 제공합니다. 정확도를 목록에 저장합니다.\n",
    "    accuracy.append(KNN.score(x_test_scale,y_test))\n",
    "    # 목록에 이웃 수 추가\n",
    "    num_neigh.append(ii)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 이웃 수를 결정하는 데 도움이 되도록 그래프에 정확도 값을 표시해 보겠습니다. 아래 코드를 실행해보세요! \n",
    "matplotlib.pyplot을 plt로 가져와야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(num_neigh,accuracy)\n",
    "plt.xlabel('Number of neighbours')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그래프에서 사용할 최적의 이웃 수는 몇입니까? 그렇게 생각하는 이유를 설명해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 결정 트리(decision tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "의사 결정 트리가 과소적합되거나 과대적합될 수도 있습니다.\n",
    "\n",
    "예를 들어, 트리에 1개의 결정 지점만 있는 경우 트리가 과소적합될 가능성이 있습니다. 반대로 트리에 여러 결정 지점이 있는 경우 트리가 과대적합될 수 있습니다. 따라서 트리가 깊을수록 트리가 과대적합될 가능성이 높아집니다. 과대적합 및 과소적합에 대한 이해를 바탕으로 데이터를 과대적합하거나 과소적합할 가능성이 있는 트리(아래 참조)를 찾아서 답변해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/dt1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './resources/dt2.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 과대적합 또는 과소적합을 제어하는 또 다른 방법은 분할을 수행하기 전에 결정 지점에 있는 최소 샘플 수를 기반으로 결정하는 것입니다. 예를 들어 트리에 날씨에 기반한 결정 지점이 있고 맑은 날이나 비오는 날로 구성된 50개의 다른 지점이 있는 경우 표본이나 데이터 지점이 꽤 많기 때문에 해당 결정 지점에서 데이터를 분할해야 합니다. 그러나 해당 날씨 결정 지점에 2개의 데이터 포인트만 있는 경우 과대적합으로 이어질 수 있으므로 날씨에 따라 데이터 포인트를 분할할 필요가 없을 수 있습니다. 따라서 결정 지점에서 표본 수를 사용하여 적합성을 제어할 수도 있습니다.\n",
    "\n",
    "이 [문서](https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3) 를 참고하여 의사결정 트리에서 과대적합 및 과소적합을 제어하는 방법에 대해 자세히 알아볼 수 있습니다. iris flower 데이터 셋트를 이용한 의사 결정 트리에서 적합성을 제어하는 데 사용할 수 있는 다른 변수는 무엇입니까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "의사 결정 트리가 Iris Flower 데이터 세트에 잘 맞도록 하는 최적의 매개변수 세트를 찾아보겠습니다. 위에서 사용한 분할 데이터 세트를 그대로 사용하여 아래의 코드를 실행해 보세요! 트리의 적합도를 제어하기 위해 사용하는 변수는 max_depth라고 알려져 있습니다. 이것은 트리의 최대 깊이를 나타냅니다. 트리가 깊을수록 과대적합될 가능성이 높아집니다. sklearn에서 트리를 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6052631578947368, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158]\n"
     ]
    }
   ],
   "source": [
    "# 각 의사 결정 트리에 대해 정확도와 가장 잘 테스트된 매개변수를 저장할 빈 목록을 만듭니다.\n",
    "accuracy = []\n",
    "depth = []\n",
    "\n",
    "# ii를 사용하여 값 1에서 9까지 반복합니다. 이것은 의사결정 트리의 max_depth 값이 됩니다.\n",
    "for ii in range(1,10):\n",
    "    # max_depth를 ii로 설정\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=ii)\n",
    "    # 데이터로 모델 훈련 또는 피팅\n",
    "    dt.fit(x_train_scale,y_train)\n",
    "    # .score는 테스트 데이터를 기반으로 모델의 정확도를 제공합니다. 정확도를 목록에 저장합니다.\n",
    "    accuracy.append(dt.score(x_test_scale,y_test))\n",
    "    # 목록에 max_depth 값 추가\n",
    "    depth.append(ii)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프의 max_depth 값에 대해 정확도 값을 표시할 수 있습니까? KNN에 사용하였던 그래프를 참조해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프에서 확인할 수 있는 최적의 max_depth 값은 무엇입니까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 배운 내용으로, 결정 지점에서 최소 샘플 수를 사용하여 과대적합 또는 과소적합을 방지할 수도 있습니다. 결정 트리 알고리즘에서 이 값은 min_samples_split에 의해 제어됩니다. 위의 코드를 복사하고 수정하여 최상의 min_samples_split 값을 찾아보세요. 2에서 15 사이의 범위를 사용할 수 있습니다. 쉽게 시각화할 수 있도록 정확도 값도 함께 표시해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프에서 가장 좋은 min_samples_split 값은 무엇입니까? 가장 높은 정확도를 갖는 가장 낮은 값을 선택하겠습니까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
